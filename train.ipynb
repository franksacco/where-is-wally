{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "8cwBIrv864j9"
   },
   "source": [
    "# UNet\n",
    "\n",
    " - UNet â€” Line by Line Explanation: https://towardsdatascience.com/unet-line-by-line-explanation-9b191c76baf5\n",
    " - Learn How to Train U-Net On Your Dataset: https://medium.com/coinmonks/learn-how-to-train-u-net-on-your-dataset-8e3f89fbd623\n",
    " - Implementation of deep learning framework -- Unet, using Keras: https://github.com/zhixuhao/unet\n",
    " - Semantic segmentation with U-Net- train, and test on your custom data in Keras: https://medium.com/@pallawi.ds/semantic-segmentation-with-u-net-train-and-test-on-your-custom-data-in-keras-39e4f972ec89"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "U2SC-qMY64kX"
   },
   "outputs": [],
   "source": [
    "IMG_WIDTH    = 256\n",
    "IMG_HEIGHT   = 256\n",
    "IMG_CHANNELS = 3\n",
    "\n",
    "BATCH_SIZE    = 14      #@param{type: \"slider\", min: 1, max: 16}\n",
    "EPOCHS        = 60      #@param{type: \"slider\", min: 5, max: 100}\n",
    "LOSS_FUNCTION = 'f1lo'  #@param['bifo', 'wbce', 'dice', 'jacc', 'f1lo']\n",
    "LEARNING_RATE = 1e-3    #@param{type: \"number\"}\n",
    "\n",
    "NAME = '%s-b%d-e%d-lr%.03f' % (LOSS_FUNCTION, BATCH_SIZE,\n",
    "                               EPOCHS, LEARNING_RATE)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "fKPF-aqj64ko"
   },
   "source": [
    "## Load dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "DenGjpMr64kq"
   },
   "outputs": [],
   "source": [
    "import glob\n",
    "import numpy as np\n",
    "from tensorflow.keras.preprocessing.image import img_to_array, load_img\n",
    "\n",
    "\n",
    "NUM_SAMPLES = len(glob.glob('data/aug/train/*_image.jpg'))\n",
    "NUM_SAMPLES_VAL = len(glob.glob('data/aug/val/*_image.jpg'))\n",
    "\n",
    "\n",
    "def process_image(image):\n",
    "    \"\"\"\n",
    "    Converting RGB values from [0, 255] to [0, 1].\n",
    "    \"\"\"\n",
    "    image /= 255.0\n",
    "    return image.astype(np.float32)\n",
    "\n",
    "def process_mask(mask):\n",
    "    \"\"\"\n",
    "    Converting RGB values from [0, 255] to {0, 1}.\n",
    "    \"\"\"\n",
    "    mask /= 255.0\n",
    "    mask[mask > 0.5] = 1\n",
    "    mask[mask <= 0.5] = 0\n",
    "    return mask.astype(np.float32)\n",
    "\n",
    "\n",
    "def gen(x_paths, y_paths, batch_size):\n",
    "    assert len(x_paths) == len(y_paths)\n",
    "    while True:\n",
    "        for i in range(len(x_paths) // batch_size):\n",
    "            x_batch = []\n",
    "            y_batch = []\n",
    "            for j in range(batch_size):\n",
    "                image = load_img(x_paths[i*batch_size + j])\n",
    "                image = img_to_array(image)\n",
    "                image = process_image(image)\n",
    "                x_batch.append(image)\n",
    "\n",
    "                mask = load_img(y_paths[i*batch_size + j],\n",
    "                                color_mode='grayscale')\n",
    "                mask = img_to_array(mask)\n",
    "                mask = process_mask(mask)\n",
    "                y_batch.append(mask)\n",
    "\n",
    "            yield (np.array(x_batch), np.array(y_batch))\n",
    "    \n",
    "\n",
    "def train_gen(batch_size):\n",
    "    return gen(\n",
    "        glob.glob('data/aug/train/*_image.jpg'),\n",
    "        glob.glob('data/aug/train/*_mask.jpg'),\n",
    "        batch_size\n",
    "    )\n",
    "\n",
    "\n",
    "def val_gen(batch_size):\n",
    "    return gen(\n",
    "        glob.glob('data/aug/val/*_image.jpg'),\n",
    "        glob.glob('data/aug/val/*_mask.jpg'),\n",
    "        batch_size\n",
    "    )"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "Fxvjudgv64lC"
   },
   "source": [
    "## Metrics\n",
    "\n",
    "- F1 score: https://en.wikipedia.org/wiki/F1_score\n",
    "- How to get accuracy, F1, precision and recall, for a keras model?: https://datascience.stackexchange.com/questions/45165/how-to-get-accuracy-f1-precision-and-recall-for-a-keras-model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "Yr1nRaI_64lE"
   },
   "outputs": [],
   "source": [
    "import tensorflow.keras.backend as K\n",
    "\n",
    "def f1_score(y_true, y_pred):\n",
    "    \"\"\"F1 score metric.\n",
    "    \n",
    "    The F1 score is the harmonic mean of the precision and\n",
    "    recall, where an F1 score reaches its best value at 1\n",
    "    (perfect precision and recall). \n",
    "    \"\"\"\n",
    "    true_positives = K.sum(K.round(K.clip(y_true * y_pred, 0, 1)))\n",
    "    predicted_positives = K.sum(K.round(K.clip(y_pred, 0, 1)))\n",
    "    possible_positives = K.sum(K.round(K.clip(y_true, 0, 1)))\n",
    "    \n",
    "    p = true_positives / (predicted_positives + K.epsilon())\n",
    "    r = true_positives / (possible_positives + K.epsilon())\n",
    "    return 2 * p * r / (p + r + K.epsilon())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "U8MiEvgC64k2"
   },
   "source": [
    "##  Loss functions\n",
    "\n",
    "- Focal loss implementation: https://github.com/hachreak/sgg-lab/blob/146ec820de913d009311537f4d9769c97ee3e0e8/sgg_lab/losses/focal_loss.py\n",
    "- Keras loss functions implementation: https://github.com/keras-team/keras/blob/master/keras/losses.py\n",
    "- Losses for Image Segmentation: https://lars76.github.io/neural-networks/object-detection/losses-for-segmentation/\n",
    "- Implementation of weighted binary crossentropy: https://stackoverflow.com/questions/46009619/keras-weighted-binary-crossentropy\n",
    "- Dice coefficient: https://en.wikipedia.org/wiki/S%C3%B8rensen%E2%80%93Dice_coefficient\n",
    "- Jaccard index: https://en.wikipedia.org/wiki/Jaccard_index\n",
    "- Implementation of Dice coefficient loss: https://gist.github.com/wassname/7793e2058c5c9dacb5212c0ac0b18a8a\n",
    "- V-Net: Fully Convolutional Neural Networks forVolumetric Medical Image Segmentation :https://arxiv.org/pdf/1606.04797v1.pdf\n",
    "- Implementation of Jaccard coefficient loss: https://gist.github.com/wassname/f1452b748efcbeb4cb9b1d059dce6f96\n",
    "- The Unknown Benefits of using a Soft-F1 Loss in Classification Systems: https://towardsdatascience.com/the-unknown-benefits-of-using-a-soft-f1-loss-in-classification-systems-753902c0105d"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "1He36F2k64k3"
   },
   "outputs": [],
   "source": [
    "def binary_focal_loss(gamma=2.0, alpha=0.25):\n",
    "    \"\"\"\n",
    "    Implementation of Focal Loss from the paper in multiclass classification\n",
    "    Formula:\n",
    "        loss = -alpha_t*((1-p_t)^gamma)*log(p_t)\n",
    "        p_t = y_pred, if y_true = 1\n",
    "        p_t = 1-y_pred, otherwise\n",
    "        alpha_t = alpha, if y_true=1\n",
    "        alpha_t = 1-alpha, otherwise\n",
    "        cross_entropy = -log(p_t)\n",
    "    Parameters:\n",
    "        alpha -- the same as wighting factor in balanced cross entropy\n",
    "        gamma -- focusing parameter for modulating factor (1-p)\n",
    "    Default value:\n",
    "        gamma -- 2.0 as mentioned in the paper\n",
    "        alpha -- 0.25 as mentioned in the paper\n",
    "    \"\"\"\n",
    "    def binary_focal(y_true, y_pred):\n",
    "        # Define epsilon so that the backpropagation will not result in NaN\n",
    "        # for 0 divisor case\n",
    "        epsilon = K.epsilon()\n",
    "        # Clip the prediciton value\n",
    "        y_pred = K.clip(y_pred, epsilon, 1.0-epsilon)\n",
    "        # Calculate p_t\n",
    "        p_t = K.where(K.equal(y_true, 1), y_pred, 1-y_pred)\n",
    "        # Calculate alpha_t\n",
    "        alpha_factor = K.ones_like(y_true)*alpha\n",
    "        alpha_t = K.where(K.equal(y_true, 1), alpha_factor, 1-alpha_factor)\n",
    "        # Calculate cross entropy\n",
    "        cross_entropy = -K.log(p_t)\n",
    "        weight = alpha_t * K.pow((1-p_t), gamma)\n",
    "        # Calculate focal loss\n",
    "        loss = weight * cross_entropy\n",
    "        # Sum the losses in mini_batch\n",
    "        loss = K.sum(loss, axis=1)\n",
    "        return loss\n",
    "\n",
    "    return binary_focal\n",
    "\n",
    "\n",
    "def weighted_binary_crossentropy(y_true, y_pred):\n",
    "    \"\"\"\n",
    "    Weighted binary crossentropy\n",
    "    \"\"\"\n",
    "    # Calulate weights    \n",
    "    zero_count = K.sum(1 - y_true)\n",
    "    one_count = K.sum(y_true)\n",
    "    tot = one_count + zero_count\n",
    "    zero_weight = 1 - zero_count / tot\n",
    "    one_weight = 1 - one_count / tot\n",
    "    \n",
    "    # Calculate the binary crossentropy\n",
    "    bce = K.binary_crossentropy(y_true, y_pred)\n",
    "    \n",
    "    # Apply the weights and return the mean error\n",
    "    weight_vector = y_true * one_weight + (1. - y_true) * zero_weight\n",
    "    return K.mean(weight_vector * bce)\n",
    "\n",
    "\n",
    "def dice_loss(y_true, y_pred, smooth=1):\n",
    "    \"\"\"\n",
    "    Dice = (2*|X & Y|)/ (|X|+ |Y|)\n",
    "         =  2*sum(|A*B|)/(sum(A^2)+sum(B^2))\n",
    "    \n",
    "    Here is a dice loss for keras which is smoothed to approximate\n",
    "    a linear (L1) loss. It ranges from 1 to 0 (no error), and\n",
    "    returns results similar to binary crossentropy.\n",
    "    \"\"\"\n",
    "    intersection = K.sum(y_true * y_pred, axis=-1)\n",
    "    union = K.sum(K.square(y_true), axis=-1) + K.sum(K.square(y_pred), axis=-1)\n",
    "    return 1 - (2. * intersection + smooth) / (union + smooth)\n",
    "\n",
    "\n",
    "def jaccard_loss(y_true, y_pred, smooth=100):\n",
    "    \"\"\"\n",
    "    Jaccard = (|X & Y|)/ (|X|+ |Y| - |X & Y|)\n",
    "            = sum(|A*B|)/(sum(|A|)+sum(|B|)-sum(|A*B|))\n",
    "    \n",
    "    The jaccard distance loss is usefull for unbalanced datasets.\n",
    "    This has been shifted so it converges on 0 and is smoothed to\n",
    "    avoid exploding or disapearing gradient.\n",
    "    \"\"\"\n",
    "    intersection = K.sum(K.abs(y_true * y_pred), axis=-1)\n",
    "    summed = K.sum(K.abs(y_true) + K.abs(y_pred), axis=-1)\n",
    "    jac = (intersection + smooth) / (summed - intersection + smooth)\n",
    "    return (1 - jac) * smooth\n",
    "\n",
    "\n",
    "def f1_loss(y_true, y_pred):\n",
    "    \"\"\"\n",
    "    The best loss function for F1-score would be, of course, the metric\n",
    "    itself: minimizing 1 âˆ’ F1 is same as maximizing F1.\n",
    "    \"\"\"\n",
    "    true_positives = K.sum(y_true * y_pred)\n",
    "    predicted_positives = K.sum(y_pred)\n",
    "    possible_positives = K.sum(y_true)\n",
    "    \n",
    "    p = true_positives / (predicted_positives + K.epsilon())\n",
    "    r = true_positives / (possible_positives + K.epsilon())\n",
    "    return 1 - (2 * p * r / (p + r + K.epsilon()))\n",
    "\n",
    "\n",
    "losses = {\n",
    "    'bifo': binary_focal_loss(),\n",
    "    'wbce': weighted_binary_crossentropy,\n",
    "    'dice': dice_loss,\n",
    "    'jacc': jaccard_loss,\n",
    "    'f1lo': f1_loss\n",
    "}"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "Y6JwRKuU64lQ"
   },
   "source": [
    "## Model definition"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from tensorflow.keras.layers import Input, Conv2D, MaxPooling2D,\\\n",
    "    Dropout, UpSampling2D, concatenate, BatchNormalization,\\\n",
    "    Activation, Conv2DTranspose\n",
    "from tensorflow.keras.models import Model\n",
    "from tensorflow.keras.optimizers import Adam"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "Rfw2y0F9TDPB"
   },
   "source": [
    "### Version 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "XnsWgFvP64lS"
   },
   "outputs": [],
   "source": [
    "def unet_v1(loss='binary_crossentropy', metrics=['accuracy'], input_size=(256, 256, 3)):\n",
    "    \"\"\"Create model for Unet network using keras.\n",
    "    \n",
    "    Parameters:\n",
    "        loss -- String (name of objective function) or objective function or Loss instance.\n",
    "        metrics -- List of metrics to be evaluated by the model during training and testing.\n",
    "        input_size -- Tuple describing input size.\n",
    "    \n",
    "    Default value:\n",
    "        loss -- 'binary_crossentropy'\n",
    "        metrics -- ['accuracy']\n",
    "        input_size -- (256, 256, 3)\n",
    "    \"\"\"\n",
    "    inputs = Input(input_size)\n",
    "    \n",
    "    conv1 = Conv2D(64, 3, activation='relu', padding='same', kernel_initializer='he_normal')(inputs)\n",
    "    conv1 = Conv2D(64, 3, activation='relu', padding='same', kernel_initializer='he_normal')(conv1)\n",
    "    pool1 = MaxPooling2D(pool_size=(2,2))(conv1)\n",
    "    \n",
    "    conv2 = Conv2D(128, 3, activation='relu', padding='same', kernel_initializer='he_normal')(pool1)\n",
    "    conv2 = Conv2D(128, 3, activation='relu', padding='same', kernel_initializer='he_normal')(conv2)\n",
    "    pool2 = MaxPooling2D(pool_size=(2,2))(conv2)\n",
    "    \n",
    "    conv3 = Conv2D(256, 3, activation='relu', padding='same', kernel_initializer='he_normal')(pool2)\n",
    "    conv3 = Conv2D(256, 3, activation='relu', padding='same', kernel_initializer='he_normal')(conv3)\n",
    "    pool3 = MaxPooling2D(pool_size=(2,2))(conv3)\n",
    "    \n",
    "    conv4 = Conv2D(512, 3, activation='relu', padding='same', kernel_initializer='he_normal')(pool3)\n",
    "    conv4 = Conv2D(512, 3, activation='relu', padding='same', kernel_initializer='he_normal')(conv4)\n",
    "    drop4 = Dropout(0.5)(conv4)\n",
    "    pool4 = MaxPooling2D(pool_size=(2, 2))(drop4)\n",
    "\n",
    "    conv5 = Conv2D(1024, 3, activation='relu', padding='same', kernel_initializer='he_normal')(pool4)\n",
    "    conv5 = Conv2D(1024, 3, activation='relu', padding='same', kernel_initializer='he_normal')(conv5)\n",
    "    drop5 = Dropout(0.5)(conv5)\n",
    "\n",
    "    up6 = Conv2D(512, 2, activation='relu', padding='same', kernel_initializer='he_normal')(UpSampling2D(size=(2,2))(drop5))\n",
    "    merge6 = concatenate([drop4,up6], axis=3)\n",
    "    conv6 = Conv2D(512, 3, activation='relu', padding='same', kernel_initializer='he_normal')(merge6)\n",
    "    conv6 = Conv2D(512, 3, activation='relu', padding='same', kernel_initializer='he_normal')(conv6)\n",
    "\n",
    "    up7 = Conv2D(256, 2, activation='relu', padding='same', kernel_initializer='he_normal')(UpSampling2D(size=(2,2))(conv6))\n",
    "    merge7 = concatenate([conv3,up7], axis=3)\n",
    "    conv7 = Conv2D(256, 3, activation='relu', padding='same', kernel_initializer='he_normal')(merge7)\n",
    "    conv7 = Conv2D(256, 3, activation='relu', padding='same', kernel_initializer='he_normal')(conv7)\n",
    "\n",
    "    up8 = Conv2D(128, 2, activation='relu', padding='same', kernel_initializer='he_normal')(UpSampling2D(size=(2,2))(conv7))\n",
    "    merge8 = concatenate([conv2,up8], axis=3)\n",
    "    conv8 = Conv2D(128, 3, activation='relu', padding='same', kernel_initializer='he_normal')(merge8)\n",
    "    conv8 = Conv2D(128, 3, activation='relu', padding='same', kernel_initializer='he_normal')(conv8)\n",
    "\n",
    "    up9 = Conv2D(64, 2, activation='relu', padding='same', kernel_initializer='he_normal')(UpSampling2D(size=(2,2))(conv8))\n",
    "    merge9 = concatenate([conv1,up9], axis=3)\n",
    "    conv9 = Conv2D(64, 3, activation='relu', padding='same', kernel_initializer='he_normal')(merge9)\n",
    "    conv9 = Conv2D(64, 3, activation='relu', padding='same', kernel_initializer='he_normal')(conv9)\n",
    "    conv9 = Conv2D(2, 3, activation='relu', padding='same', kernel_initializer='he_normal')(conv9)\n",
    "    \n",
    "    outputs = Conv2D(1, 1, activation='sigmoid')(conv9)\n",
    "\n",
    "    model = Model(inputs=[inputs], outputs=[outputs])\n",
    "    model.compile(\n",
    "        optimizer=Adam(learning_rate=LEARNING_RATE),\n",
    "        loss=loss,\n",
    "        metrics=metrics\n",
    "    )\n",
    "    return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 1000
    },
    "colab_type": "code",
    "executionInfo": {
     "elapsed": 38998,
     "status": "ok",
     "timestamp": 1588953548827,
     "user": {
      "displayName": "Francesco SACCANI",
      "photoUrl": "https://lh3.googleusercontent.com/a-/AOh14GiK1QlwNLRwoAq-pAnoW8HH9h9h2SvqIHGIEuyL=s64",
      "userId": "03506189413873966593"
     },
     "user_tz": -120
    },
    "id": "o9aPdDnC64lg",
    "outputId": "160cc797-5b1e-42ee-e1b0-49ae66c128e0",
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"model_1\"\n",
      "__________________________________________________________________________________________________\n",
      "Layer (type)                    Output Shape         Param #     Connected to                     \n",
      "==================================================================================================\n",
      "input_1 (InputLayer)            (None, 256, 256, 3)  0                                            \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_1 (Conv2D)               (None, 256, 256, 64) 1792        input_1[0][0]                    \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_2 (Conv2D)               (None, 256, 256, 64) 36928       conv2d_1[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "max_pooling2d_1 (MaxPooling2D)  (None, 128, 128, 64) 0           conv2d_2[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_3 (Conv2D)               (None, 128, 128, 128 73856       max_pooling2d_1[0][0]            \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_4 (Conv2D)               (None, 128, 128, 128 147584      conv2d_3[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "max_pooling2d_2 (MaxPooling2D)  (None, 64, 64, 128)  0           conv2d_4[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_5 (Conv2D)               (None, 64, 64, 256)  295168      max_pooling2d_2[0][0]            \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_6 (Conv2D)               (None, 64, 64, 256)  590080      conv2d_5[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "max_pooling2d_3 (MaxPooling2D)  (None, 32, 32, 256)  0           conv2d_6[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_7 (Conv2D)               (None, 32, 32, 512)  1180160     max_pooling2d_3[0][0]            \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_8 (Conv2D)               (None, 32, 32, 512)  2359808     conv2d_7[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "dropout_1 (Dropout)             (None, 32, 32, 512)  0           conv2d_8[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "max_pooling2d_4 (MaxPooling2D)  (None, 16, 16, 512)  0           dropout_1[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_9 (Conv2D)               (None, 16, 16, 1024) 4719616     max_pooling2d_4[0][0]            \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_10 (Conv2D)              (None, 16, 16, 1024) 9438208     conv2d_9[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "dropout_2 (Dropout)             (None, 16, 16, 1024) 0           conv2d_10[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "up_sampling2d_1 (UpSampling2D)  (None, 32, 32, 1024) 0           dropout_2[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_11 (Conv2D)              (None, 32, 32, 512)  2097664     up_sampling2d_1[0][0]            \n",
      "__________________________________________________________________________________________________\n",
      "concatenate_1 (Concatenate)     (None, 32, 32, 1024) 0           dropout_1[0][0]                  \n",
      "                                                                 conv2d_11[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_12 (Conv2D)              (None, 32, 32, 512)  4719104     concatenate_1[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_13 (Conv2D)              (None, 32, 32, 512)  2359808     conv2d_12[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "up_sampling2d_2 (UpSampling2D)  (None, 64, 64, 512)  0           conv2d_13[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_14 (Conv2D)              (None, 64, 64, 256)  524544      up_sampling2d_2[0][0]            \n",
      "__________________________________________________________________________________________________\n",
      "concatenate_2 (Concatenate)     (None, 64, 64, 512)  0           conv2d_6[0][0]                   \n",
      "                                                                 conv2d_14[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_15 (Conv2D)              (None, 64, 64, 256)  1179904     concatenate_2[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_16 (Conv2D)              (None, 64, 64, 256)  590080      conv2d_15[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "up_sampling2d_3 (UpSampling2D)  (None, 128, 128, 256 0           conv2d_16[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_17 (Conv2D)              (None, 128, 128, 128 131200      up_sampling2d_3[0][0]            \n",
      "__________________________________________________________________________________________________\n",
      "concatenate_3 (Concatenate)     (None, 128, 128, 256 0           conv2d_4[0][0]                   \n",
      "                                                                 conv2d_17[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_18 (Conv2D)              (None, 128, 128, 128 295040      concatenate_3[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_19 (Conv2D)              (None, 128, 128, 128 147584      conv2d_18[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "up_sampling2d_4 (UpSampling2D)  (None, 256, 256, 128 0           conv2d_19[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_20 (Conv2D)              (None, 256, 256, 64) 32832       up_sampling2d_4[0][0]            \n",
      "__________________________________________________________________________________________________\n",
      "concatenate_4 (Concatenate)     (None, 256, 256, 128 0           conv2d_2[0][0]                   \n",
      "                                                                 conv2d_20[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_21 (Conv2D)              (None, 256, 256, 64) 73792       concatenate_4[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_22 (Conv2D)              (None, 256, 256, 64) 36928       conv2d_21[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_23 (Conv2D)              (None, 256, 256, 2)  1154        conv2d_22[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_24 (Conv2D)              (None, 256, 256, 1)  3           conv2d_23[0][0]                  \n",
      "==================================================================================================\n",
      "Total params: 31,032,837\n",
      "Trainable params: 31,032,837\n",
      "Non-trainable params: 0\n",
      "__________________________________________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "unet_v1().summary()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "5rJPnhETiDu8"
   },
   "source": [
    "### Version 2\n",
    "\n",
    " - U-Net for segmenting seismic images with keras: https://www.depends-on-the-definition.com/unet-keras-segmenting-images/"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "Kq7IyYNAhzju"
   },
   "outputs": [],
   "source": [
    "def conv2d_block(input_tensor, n_filters, kernel_size=3, batchnorm=True):\n",
    "    # first layer\n",
    "    x = Conv2D(filters=n_filters, kernel_size=(kernel_size, kernel_size), kernel_initializer=\"he_normal\",\n",
    "               padding=\"same\")(input_tensor)\n",
    "    if batchnorm:\n",
    "        x = BatchNormalization()(x)\n",
    "    x = Activation(\"relu\")(x)\n",
    "    # second layer\n",
    "    x = Conv2D(filters=n_filters, kernel_size=(kernel_size, kernel_size), kernel_initializer=\"he_normal\",\n",
    "               padding=\"same\")(x)\n",
    "    if batchnorm:\n",
    "        x = BatchNormalization()(x)\n",
    "    x = Activation(\"relu\")(x)\n",
    "    return x\n",
    "\n",
    "def unet_v2(loss='binary_crossentropy',\n",
    "            metrics=['accuracy'],\n",
    "            input_size=(256, 256, 3),\n",
    "            n_filters=16,\n",
    "            dropout=0.05,\n",
    "            batchnorm=True):\n",
    "    \"\"\"Create model for Unet network using keras.\n",
    "    \n",
    "    Parameters:\n",
    "        loss -- String (name of objective function) or objective function or Loss instance.\n",
    "        metrics -- List of metrics to be evaluated by the model during training and testing.\n",
    "        input_size -- Tuple describing input size.\n",
    "        n_filters --\n",
    "        dropout --\n",
    "        batchnorm --\n",
    "    \n",
    "    Default value:\n",
    "        loss -- 'binary_crossentropy'\n",
    "        metrics -- ['accuracy']\n",
    "        input_size -- (256, 256, 3)\n",
    "    \"\"\"\n",
    "    inputs = Input(input_size, name='input')\n",
    "\n",
    "    # contracting path\n",
    "    c1 = conv2d_block(inputs, n_filters=n_filters*1, kernel_size=3, batchnorm=batchnorm)\n",
    "    p1 = MaxPooling2D((2, 2)) (c1)\n",
    "    p1 = Dropout(dropout*0.5)(p1)\n",
    "\n",
    "    c2 = conv2d_block(p1, n_filters=n_filters*2, kernel_size=3, batchnorm=batchnorm)\n",
    "    p2 = MaxPooling2D((2, 2)) (c2)\n",
    "    p2 = Dropout(dropout)(p2)\n",
    "\n",
    "    c3 = conv2d_block(p2, n_filters=n_filters*4, kernel_size=3, batchnorm=batchnorm)\n",
    "    p3 = MaxPooling2D((2, 2)) (c3)\n",
    "    p3 = Dropout(dropout)(p3)\n",
    "\n",
    "    c4 = conv2d_block(p3, n_filters=n_filters*8, kernel_size=3, batchnorm=batchnorm)\n",
    "    p4 = MaxPooling2D(pool_size=(2, 2)) (c4)\n",
    "    p4 = Dropout(dropout)(p4)\n",
    "    \n",
    "    c5 = conv2d_block(p4, n_filters=n_filters*16, kernel_size=3, batchnorm=batchnorm)\n",
    "    \n",
    "    # expansive path\n",
    "    u6 = Conv2DTranspose(n_filters*8, (3, 3), strides=(2, 2), padding='same') (c5)\n",
    "    u6 = concatenate([u6, c4])\n",
    "    u6 = Dropout(dropout)(u6)\n",
    "    c6 = conv2d_block(u6, n_filters=n_filters*8, kernel_size=3, batchnorm=batchnorm)\n",
    "\n",
    "    u7 = Conv2DTranspose(n_filters*4, (3, 3), strides=(2, 2), padding='same') (c6)\n",
    "    u7 = concatenate([u7, c3])\n",
    "    u7 = Dropout(dropout)(u7)\n",
    "    c7 = conv2d_block(u7, n_filters=n_filters*4, kernel_size=3, batchnorm=batchnorm)\n",
    "\n",
    "    u8 = Conv2DTranspose(n_filters*2, (3, 3), strides=(2, 2), padding='same') (c7)\n",
    "    u8 = concatenate([u8, c2])\n",
    "    u8 = Dropout(dropout)(u8)\n",
    "    c8 = conv2d_block(u8, n_filters=n_filters*2, kernel_size=3, batchnorm=batchnorm)\n",
    "\n",
    "    u9 = Conv2DTranspose(n_filters*1, (3, 3), strides=(2, 2), padding='same') (c8)\n",
    "    u9 = concatenate([u9, c1], axis=3)\n",
    "    u9 = Dropout(dropout)(u9)\n",
    "    c9 = conv2d_block(u9, n_filters=n_filters*1, kernel_size=3, batchnorm=batchnorm)\n",
    "    \n",
    "    outputs = Conv2D(1, (1, 1), activation='sigmoid') (c9)\n",
    "\n",
    "    model = Model(inputs=[inputs], outputs=[outputs])\n",
    "    model.compile(\n",
    "        optimizer=Adam(learning_rate=LEARNING_RATE),\n",
    "        loss=loss,\n",
    "        metrics=metrics\n",
    "    )\n",
    "    return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 1000
    },
    "colab_type": "code",
    "executionInfo": {
     "elapsed": 74699,
     "status": "ok",
     "timestamp": 1588953584560,
     "user": {
      "displayName": "Francesco SACCANI",
      "photoUrl": "https://lh3.googleusercontent.com/a-/AOh14GiK1QlwNLRwoAq-pAnoW8HH9h9h2SvqIHGIEuyL=s64",
      "userId": "03506189413873966593"
     },
     "user_tz": -120
    },
    "id": "f3g4DPbzjPUJ",
    "outputId": "4c65bc10-0e20-4175-f292-d4650245eb11",
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"model_2\"\n",
      "__________________________________________________________________________________________________\n",
      "Layer (type)                    Output Shape         Param #     Connected to                     \n",
      "==================================================================================================\n",
      "input (InputLayer)              (None, 256, 256, 3)  0                                            \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_25 (Conv2D)              (None, 256, 256, 16) 448         input[0][0]                      \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_1 (BatchNor (None, 256, 256, 16) 64          conv2d_25[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "activation_1 (Activation)       (None, 256, 256, 16) 0           batch_normalization_1[0][0]      \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_26 (Conv2D)              (None, 256, 256, 16) 2320        activation_1[0][0]               \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_2 (BatchNor (None, 256, 256, 16) 64          conv2d_26[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "activation_2 (Activation)       (None, 256, 256, 16) 0           batch_normalization_2[0][0]      \n",
      "__________________________________________________________________________________________________\n",
      "max_pooling2d_5 (MaxPooling2D)  (None, 128, 128, 16) 0           activation_2[0][0]               \n",
      "__________________________________________________________________________________________________\n",
      "dropout_3 (Dropout)             (None, 128, 128, 16) 0           max_pooling2d_5[0][0]            \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_27 (Conv2D)              (None, 128, 128, 32) 4640        dropout_3[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_3 (BatchNor (None, 128, 128, 32) 128         conv2d_27[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "activation_3 (Activation)       (None, 128, 128, 32) 0           batch_normalization_3[0][0]      \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_28 (Conv2D)              (None, 128, 128, 32) 9248        activation_3[0][0]               \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_4 (BatchNor (None, 128, 128, 32) 128         conv2d_28[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "activation_4 (Activation)       (None, 128, 128, 32) 0           batch_normalization_4[0][0]      \n",
      "__________________________________________________________________________________________________\n",
      "max_pooling2d_6 (MaxPooling2D)  (None, 64, 64, 32)   0           activation_4[0][0]               \n",
      "__________________________________________________________________________________________________\n",
      "dropout_4 (Dropout)             (None, 64, 64, 32)   0           max_pooling2d_6[0][0]            \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_29 (Conv2D)              (None, 64, 64, 64)   18496       dropout_4[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_5 (BatchNor (None, 64, 64, 64)   256         conv2d_29[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "activation_5 (Activation)       (None, 64, 64, 64)   0           batch_normalization_5[0][0]      \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_30 (Conv2D)              (None, 64, 64, 64)   36928       activation_5[0][0]               \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_6 (BatchNor (None, 64, 64, 64)   256         conv2d_30[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "activation_6 (Activation)       (None, 64, 64, 64)   0           batch_normalization_6[0][0]      \n",
      "__________________________________________________________________________________________________\n",
      "max_pooling2d_7 (MaxPooling2D)  (None, 32, 32, 64)   0           activation_6[0][0]               \n",
      "__________________________________________________________________________________________________\n",
      "dropout_5 (Dropout)             (None, 32, 32, 64)   0           max_pooling2d_7[0][0]            \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_31 (Conv2D)              (None, 32, 32, 128)  73856       dropout_5[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_7 (BatchNor (None, 32, 32, 128)  512         conv2d_31[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "activation_7 (Activation)       (None, 32, 32, 128)  0           batch_normalization_7[0][0]      \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_32 (Conv2D)              (None, 32, 32, 128)  147584      activation_7[0][0]               \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_8 (BatchNor (None, 32, 32, 128)  512         conv2d_32[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "activation_8 (Activation)       (None, 32, 32, 128)  0           batch_normalization_8[0][0]      \n",
      "__________________________________________________________________________________________________\n",
      "max_pooling2d_8 (MaxPooling2D)  (None, 16, 16, 128)  0           activation_8[0][0]               \n",
      "__________________________________________________________________________________________________\n",
      "dropout_6 (Dropout)             (None, 16, 16, 128)  0           max_pooling2d_8[0][0]            \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_33 (Conv2D)              (None, 16, 16, 256)  295168      dropout_6[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_9 (BatchNor (None, 16, 16, 256)  1024        conv2d_33[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "activation_9 (Activation)       (None, 16, 16, 256)  0           batch_normalization_9[0][0]      \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_34 (Conv2D)              (None, 16, 16, 256)  590080      activation_9[0][0]               \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_10 (BatchNo (None, 16, 16, 256)  1024        conv2d_34[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "activation_10 (Activation)      (None, 16, 16, 256)  0           batch_normalization_10[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_transpose_1 (Conv2DTrans (None, 32, 32, 128)  295040      activation_10[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "concatenate_5 (Concatenate)     (None, 32, 32, 256)  0           conv2d_transpose_1[0][0]         \n",
      "                                                                 activation_8[0][0]               \n",
      "__________________________________________________________________________________________________\n",
      "dropout_7 (Dropout)             (None, 32, 32, 256)  0           concatenate_5[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_35 (Conv2D)              (None, 32, 32, 128)  295040      dropout_7[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_11 (BatchNo (None, 32, 32, 128)  512         conv2d_35[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "activation_11 (Activation)      (None, 32, 32, 128)  0           batch_normalization_11[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_36 (Conv2D)              (None, 32, 32, 128)  147584      activation_11[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_12 (BatchNo (None, 32, 32, 128)  512         conv2d_36[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "activation_12 (Activation)      (None, 32, 32, 128)  0           batch_normalization_12[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_transpose_2 (Conv2DTrans (None, 64, 64, 64)   73792       activation_12[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "concatenate_6 (Concatenate)     (None, 64, 64, 128)  0           conv2d_transpose_2[0][0]         \n",
      "                                                                 activation_6[0][0]               \n",
      "__________________________________________________________________________________________________\n",
      "dropout_8 (Dropout)             (None, 64, 64, 128)  0           concatenate_6[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_37 (Conv2D)              (None, 64, 64, 64)   73792       dropout_8[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_13 (BatchNo (None, 64, 64, 64)   256         conv2d_37[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "activation_13 (Activation)      (None, 64, 64, 64)   0           batch_normalization_13[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_38 (Conv2D)              (None, 64, 64, 64)   36928       activation_13[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_14 (BatchNo (None, 64, 64, 64)   256         conv2d_38[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "activation_14 (Activation)      (None, 64, 64, 64)   0           batch_normalization_14[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_transpose_3 (Conv2DTrans (None, 128, 128, 32) 18464       activation_14[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "concatenate_7 (Concatenate)     (None, 128, 128, 64) 0           conv2d_transpose_3[0][0]         \n",
      "                                                                 activation_4[0][0]               \n",
      "__________________________________________________________________________________________________\n",
      "dropout_9 (Dropout)             (None, 128, 128, 64) 0           concatenate_7[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_39 (Conv2D)              (None, 128, 128, 32) 18464       dropout_9[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_15 (BatchNo (None, 128, 128, 32) 128         conv2d_39[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "activation_15 (Activation)      (None, 128, 128, 32) 0           batch_normalization_15[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_40 (Conv2D)              (None, 128, 128, 32) 9248        activation_15[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_16 (BatchNo (None, 128, 128, 32) 128         conv2d_40[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "activation_16 (Activation)      (None, 128, 128, 32) 0           batch_normalization_16[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_transpose_4 (Conv2DTrans (None, 256, 256, 16) 4624        activation_16[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "concatenate_8 (Concatenate)     (None, 256, 256, 32) 0           conv2d_transpose_4[0][0]         \n",
      "                                                                 activation_2[0][0]               \n",
      "__________________________________________________________________________________________________\n",
      "dropout_10 (Dropout)            (None, 256, 256, 32) 0           concatenate_8[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_41 (Conv2D)              (None, 256, 256, 16) 4624        dropout_10[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_17 (BatchNo (None, 256, 256, 16) 64          conv2d_41[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "activation_17 (Activation)      (None, 256, 256, 16) 0           batch_normalization_17[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_42 (Conv2D)              (None, 256, 256, 16) 2320        activation_17[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_18 (BatchNo (None, 256, 256, 16) 64          conv2d_42[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "activation_18 (Activation)      (None, 256, 256, 16) 0           batch_normalization_18[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_43 (Conv2D)              (None, 256, 256, 1)  17          activation_18[0][0]              \n",
      "==================================================================================================\n",
      "Total params: 2,164,593\n",
      "Trainable params: 2,161,649\n",
      "Non-trainable params: 2,944\n",
      "__________________________________________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "unet_v2().summary()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "4fVXIFO364lo"
   },
   "source": [
    "## Training"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "QjihGfPe64ly"
   },
   "outputs": [],
   "source": [
    "from tensorflow.keras.callbacks import EarlyStopping, ModelCheckpoint\n",
    "\n",
    "earlystopper = EarlyStopping(\n",
    "    monitor='val_loss',\n",
    "    patience=10,\n",
    "    verbose=1\n",
    ")\n",
    "checkpointer = ModelCheckpoint(\n",
    "    'models/unet_v2.' + NAME + '.{epoch:02d}.hdf5',\n",
    "    monitor='val_f1_score',\n",
    "    save_best_only=True,\n",
    "    save_weights_only=False,\n",
    "    mode='max',\n",
    "    verbose=1\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 1000
    },
    "colab_type": "code",
    "executionInfo": {
     "elapsed": 1009292,
     "status": "ok",
     "timestamp": 1588957374108,
     "user": {
      "displayName": "Francesco SACCANI",
      "photoUrl": "https://lh3.googleusercontent.com/a-/AOh14GiK1QlwNLRwoAq-pAnoW8HH9h9h2SvqIHGIEuyL=s64",
      "userId": "03506189413873966593"
     },
     "user_tz": -120
    },
    "id": "CUwmxdU564l7",
    "outputId": "da55ee15-4e60-4fed-f99f-6684609cd16e",
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/60\n",
      "31/31 [==============================] - 24s 786ms/step - loss: 0.9445 - f1_score: 0.0555 - val_loss: 0.9680 - val_f1_score: 0.0302\n",
      "\n",
      "Epoch 00001: val_f1_score improved from -inf to 0.03025, saving model to models/unet_v2.f1lo-b14-e60-lr0.001.01.hdf5\n",
      "Epoch 2/60\n",
      "31/31 [==============================] - 18s 586ms/step - loss: 0.9113 - f1_score: 0.0887 - val_loss: 0.9705 - val_f1_score: 0.0248\n",
      "\n",
      "Epoch 00002: val_f1_score did not improve from 0.03025\n",
      "Epoch 3/60\n",
      "31/31 [==============================] - 18s 585ms/step - loss: 0.8753 - f1_score: 0.1247 - val_loss: 0.9545 - val_f1_score: 0.0421\n",
      "\n",
      "Epoch 00003: val_f1_score improved from 0.03025 to 0.04210, saving model to models/unet_v2.f1lo-b14-e60-lr0.001.03.hdf5\n",
      "Epoch 4/60\n",
      "31/31 [==============================] - 18s 585ms/step - loss: 0.8211 - f1_score: 0.1789 - val_loss: 0.9039 - val_f1_score: 0.0894\n",
      "\n",
      "Epoch 00004: val_f1_score improved from 0.04210 to 0.08937, saving model to models/unet_v2.f1lo-b14-e60-lr0.001.04.hdf5\n",
      "Epoch 5/60\n",
      "31/31 [==============================] - 18s 586ms/step - loss: 0.7496 - f1_score: 0.2504 - val_loss: 0.8427 - val_f1_score: 0.1479\n",
      "\n",
      "Epoch 00005: val_f1_score improved from 0.08937 to 0.14789, saving model to models/unet_v2.f1lo-b14-e60-lr0.001.05.hdf5\n",
      "Epoch 6/60\n",
      "31/31 [==============================] - 18s 585ms/step - loss: 0.6511 - f1_score: 0.3489 - val_loss: 0.7751 - val_f1_score: 0.2064\n",
      "\n",
      "Epoch 00006: val_f1_score improved from 0.14789 to 0.20637, saving model to models/unet_v2.f1lo-b14-e60-lr0.001.06.hdf5\n",
      "Epoch 7/60\n",
      "31/31 [==============================] - 18s 586ms/step - loss: 0.5273 - f1_score: 0.4727 - val_loss: 0.6797 - val_f1_score: 0.3029\n",
      "\n",
      "Epoch 00007: val_f1_score improved from 0.20637 to 0.30294, saving model to models/unet_v2.f1lo-b14-e60-lr0.001.07.hdf5\n",
      "Epoch 8/60\n",
      "31/31 [==============================] - 18s 586ms/step - loss: 0.4051 - f1_score: 0.5949 - val_loss: 0.5508 - val_f1_score: 0.4247\n",
      "\n",
      "Epoch 00008: val_f1_score improved from 0.30294 to 0.42470, saving model to models/unet_v2.f1lo-b14-e60-lr0.001.08.hdf5\n",
      "Epoch 9/60\n",
      "31/31 [==============================] - 18s 586ms/step - loss: 0.3048 - f1_score: 0.6952 - val_loss: 0.4554 - val_f1_score: 0.5144\n",
      "\n",
      "Epoch 00009: val_f1_score improved from 0.42470 to 0.51441, saving model to models/unet_v2.f1lo-b14-e60-lr0.001.09.hdf5\n",
      "Epoch 10/60\n",
      "31/31 [==============================] - 18s 589ms/step - loss: 0.2343 - f1_score: 0.7657 - val_loss: 0.3325 - val_f1_score: 0.6377\n",
      "\n",
      "Epoch 00010: val_f1_score improved from 0.51441 to 0.63774, saving model to models/unet_v2.f1lo-b14-e60-lr0.001.10.hdf5\n",
      "Epoch 11/60\n",
      "31/31 [==============================] - 18s 585ms/step - loss: 0.1853 - f1_score: 0.8147 - val_loss: 0.3963 - val_f1_score: 0.5779\n",
      "\n",
      "Epoch 00011: val_f1_score did not improve from 0.63774\n",
      "Epoch 12/60\n",
      "31/31 [==============================] - 18s 587ms/step - loss: 0.1593 - f1_score: 0.8407 - val_loss: 0.3682 - val_f1_score: 0.5966\n",
      "\n",
      "Epoch 00012: val_f1_score did not improve from 0.63774\n",
      "Epoch 13/60\n",
      "31/31 [==============================] - 18s 586ms/step - loss: 0.1597 - f1_score: 0.8403 - val_loss: 0.3171 - val_f1_score: 0.6966\n",
      "\n",
      "Epoch 00013: val_f1_score improved from 0.63774 to 0.69662, saving model to models/unet_v2.f1lo-b14-e60-lr0.001.13.hdf5\n",
      "Epoch 14/60\n",
      "31/31 [==============================] - 18s 585ms/step - loss: 0.1205 - f1_score: 0.8795 - val_loss: 0.1526 - val_f1_score: 0.8314\n",
      "\n",
      "Epoch 00014: val_f1_score improved from 0.69662 to 0.83140, saving model to models/unet_v2.f1lo-b14-e60-lr0.001.14.hdf5\n",
      "Epoch 15/60\n",
      "31/31 [==============================] - 18s 585ms/step - loss: 0.1021 - f1_score: 0.8979 - val_loss: 0.2337 - val_f1_score: 0.7464\n",
      "\n",
      "Epoch 00015: val_f1_score did not improve from 0.83140\n",
      "Epoch 16/60\n",
      "31/31 [==============================] - 18s 587ms/step - loss: 0.0898 - f1_score: 0.9102 - val_loss: 0.1886 - val_f1_score: 0.7781\n",
      "\n",
      "Epoch 00016: val_f1_score did not improve from 0.83140\n",
      "Epoch 17/60\n",
      "31/31 [==============================] - 18s 587ms/step - loss: 0.0821 - f1_score: 0.9179 - val_loss: 0.1370 - val_f1_score: 0.8432\n",
      "\n",
      "Epoch 00017: val_f1_score improved from 0.83140 to 0.84316, saving model to models/unet_v2.f1lo-b14-e60-lr0.001.17.hdf5\n",
      "Epoch 18/60\n",
      "31/31 [==============================] - 18s 587ms/step - loss: 0.0763 - f1_score: 0.9237 - val_loss: 0.1903 - val_f1_score: 0.7828\n",
      "\n",
      "Epoch 00018: val_f1_score did not improve from 0.84316\n",
      "Epoch 19/60\n",
      "31/31 [==============================] - 18s 585ms/step - loss: 0.0761 - f1_score: 0.9239 - val_loss: 0.1156 - val_f1_score: 0.8586\n",
      "\n",
      "Epoch 00019: val_f1_score improved from 0.84316 to 0.85856, saving model to models/unet_v2.f1lo-b14-e60-lr0.001.19.hdf5\n",
      "Epoch 20/60\n",
      "31/31 [==============================] - 18s 588ms/step - loss: 0.0716 - f1_score: 0.9284 - val_loss: 0.1328 - val_f1_score: 0.8466\n",
      "\n",
      "Epoch 00020: val_f1_score did not improve from 0.85856\n",
      "Epoch 21/60\n",
      "31/31 [==============================] - 18s 586ms/step - loss: 0.0668 - f1_score: 0.9332 - val_loss: 0.0983 - val_f1_score: 0.8826\n",
      "\n",
      "Epoch 00021: val_f1_score improved from 0.85856 to 0.88256, saving model to models/unet_v2.f1lo-b14-e60-lr0.001.21.hdf5\n",
      "Epoch 22/60\n",
      "31/31 [==============================] - 18s 586ms/step - loss: 0.0614 - f1_score: 0.9386 - val_loss: 0.0794 - val_f1_score: 0.9103\n",
      "\n",
      "Epoch 00022: val_f1_score improved from 0.88256 to 0.91035, saving model to models/unet_v2.f1lo-b14-e60-lr0.001.22.hdf5\n",
      "Epoch 23/60\n",
      "31/31 [==============================] - 18s 588ms/step - loss: 0.0561 - f1_score: 0.9439 - val_loss: 0.0847 - val_f1_score: 0.9056\n",
      "\n",
      "Epoch 00023: val_f1_score did not improve from 0.91035\n",
      "Epoch 24/60\n",
      "31/31 [==============================] - 18s 587ms/step - loss: 0.0523 - f1_score: 0.9477 - val_loss: 0.0898 - val_f1_score: 0.9038\n",
      "\n",
      "Epoch 00024: val_f1_score did not improve from 0.91035\n",
      "Epoch 25/60\n",
      "31/31 [==============================] - 18s 585ms/step - loss: 0.0512 - f1_score: 0.9488 - val_loss: 0.0632 - val_f1_score: 0.9289\n",
      "\n",
      "Epoch 00025: val_f1_score improved from 0.91035 to 0.92887, saving model to models/unet_v2.f1lo-b14-e60-lr0.001.25.hdf5\n",
      "Epoch 26/60\n",
      "31/31 [==============================] - 18s 585ms/step - loss: 0.0494 - f1_score: 0.9506 - val_loss: 0.0869 - val_f1_score: 0.9020\n",
      "\n",
      "Epoch 00026: val_f1_score did not improve from 0.92887\n",
      "Epoch 27/60\n",
      "31/31 [==============================] - 18s 586ms/step - loss: 0.0481 - f1_score: 0.9519 - val_loss: 0.0962 - val_f1_score: 0.8967\n",
      "\n",
      "Epoch 00027: val_f1_score did not improve from 0.92887\n",
      "Epoch 28/60\n",
      "31/31 [==============================] - 18s 585ms/step - loss: 0.0441 - f1_score: 0.9559 - val_loss: 0.0892 - val_f1_score: 0.9074\n",
      "\n",
      "Epoch 00028: val_f1_score did not improve from 0.92887\n",
      "Epoch 29/60\n",
      "31/31 [==============================] - 18s 585ms/step - loss: 0.0423 - f1_score: 0.9577 - val_loss: 0.0647 - val_f1_score: 0.9271\n",
      "\n",
      "Epoch 00029: val_f1_score did not improve from 0.92887\n",
      "Epoch 30/60\n",
      "31/31 [==============================] - 18s 582ms/step - loss: 0.0409 - f1_score: 0.9591 - val_loss: 0.0672 - val_f1_score: 0.9235\n",
      "\n",
      "Epoch 00030: val_f1_score did not improve from 0.92887\n",
      "Epoch 31/60\n",
      "31/31 [==============================] - 18s 584ms/step - loss: 0.0393 - f1_score: 0.9607 - val_loss: 0.0547 - val_f1_score: 0.9393\n",
      "\n",
      "Epoch 00031: val_f1_score improved from 0.92887 to 0.93926, saving model to models/unet_v2.f1lo-b14-e60-lr0.001.31.hdf5\n",
      "Epoch 32/60\n",
      "31/31 [==============================] - 18s 584ms/step - loss: 0.0389 - f1_score: 0.9611 - val_loss: 0.0676 - val_f1_score: 0.9223\n",
      "\n",
      "Epoch 00032: val_f1_score did not improve from 0.93926\n",
      "Epoch 33/60\n",
      "31/31 [==============================] - 18s 584ms/step - loss: 0.0382 - f1_score: 0.9618 - val_loss: 0.0695 - val_f1_score: 0.9233\n",
      "\n",
      "Epoch 00033: val_f1_score did not improve from 0.93926\n",
      "Epoch 34/60\n",
      "31/31 [==============================] - 18s 584ms/step - loss: 0.0377 - f1_score: 0.9623 - val_loss: 0.0650 - val_f1_score: 0.9279\n",
      "\n",
      "Epoch 00034: val_f1_score did not improve from 0.93926\n",
      "Epoch 35/60\n",
      "31/31 [==============================] - 18s 586ms/step - loss: 0.0375 - f1_score: 0.9625 - val_loss: 0.0691 - val_f1_score: 0.9214\n",
      "\n",
      "Epoch 00035: val_f1_score did not improve from 0.93926\n",
      "Epoch 36/60\n",
      "31/31 [==============================] - 18s 587ms/step - loss: 0.0354 - f1_score: 0.9646 - val_loss: 0.0642 - val_f1_score: 0.9255\n",
      "\n",
      "Epoch 00036: val_f1_score did not improve from 0.93926\n",
      "Epoch 37/60\n",
      "31/31 [==============================] - 18s 587ms/step - loss: 0.0344 - f1_score: 0.9656 - val_loss: 0.0606 - val_f1_score: 0.9315\n",
      "\n",
      "Epoch 00037: val_f1_score did not improve from 0.93926\n",
      "Epoch 38/60\n",
      "31/31 [==============================] - 18s 585ms/step - loss: 0.0339 - f1_score: 0.9661 - val_loss: 0.0546 - val_f1_score: 0.9355\n",
      "\n",
      "Epoch 00038: val_f1_score did not improve from 0.93926\n",
      "Epoch 39/60\n",
      "31/31 [==============================] - 18s 585ms/step - loss: 0.0329 - f1_score: 0.9671 - val_loss: 0.0522 - val_f1_score: 0.9405\n",
      "\n",
      "Epoch 00039: val_f1_score improved from 0.93926 to 0.94046, saving model to models/unet_v2.f1lo-b14-e60-lr0.001.39.hdf5\n",
      "Epoch 40/60\n",
      "31/31 [==============================] - 18s 585ms/step - loss: 0.0328 - f1_score: 0.9672 - val_loss: 0.0588 - val_f1_score: 0.9330\n",
      "\n",
      "Epoch 00040: val_f1_score did not improve from 0.94046\n",
      "Epoch 41/60\n",
      "31/31 [==============================] - 18s 586ms/step - loss: 0.0326 - f1_score: 0.9674 - val_loss: 0.0584 - val_f1_score: 0.9311\n",
      "\n",
      "Epoch 00041: val_f1_score did not improve from 0.94046\n",
      "Epoch 42/60\n",
      "31/31 [==============================] - 18s 583ms/step - loss: 0.0323 - f1_score: 0.9677 - val_loss: 0.0557 - val_f1_score: 0.9365\n",
      "\n",
      "Epoch 00042: val_f1_score did not improve from 0.94046\n",
      "Epoch 43/60\n",
      "31/31 [==============================] - 18s 584ms/step - loss: 0.0315 - f1_score: 0.9685 - val_loss: 0.0511 - val_f1_score: 0.9425\n",
      "\n",
      "Epoch 00043: val_f1_score improved from 0.94046 to 0.94252, saving model to models/unet_v2.f1lo-b14-e60-lr0.001.43.hdf5\n",
      "Epoch 44/60\n",
      "31/31 [==============================] - 18s 586ms/step - loss: 0.0312 - f1_score: 0.9688 - val_loss: 0.0492 - val_f1_score: 0.9459\n",
      "\n",
      "Epoch 00044: val_f1_score improved from 0.94252 to 0.94586, saving model to models/unet_v2.f1lo-b14-e60-lr0.001.44.hdf5\n",
      "Epoch 45/60\n",
      "31/31 [==============================] - 18s 586ms/step - loss: 0.0313 - f1_score: 0.9687 - val_loss: 0.0503 - val_f1_score: 0.9455\n",
      "\n",
      "Epoch 00045: val_f1_score did not improve from 0.94586\n",
      "Epoch 46/60\n",
      "31/31 [==============================] - 18s 587ms/step - loss: 0.0317 - f1_score: 0.9683 - val_loss: 0.0524 - val_f1_score: 0.9396\n",
      "\n",
      "Epoch 00046: val_f1_score did not improve from 0.94586\n",
      "Epoch 47/60\n",
      "31/31 [==============================] - 18s 587ms/step - loss: 0.0311 - f1_score: 0.9689 - val_loss: 0.0515 - val_f1_score: 0.9349\n",
      "\n",
      "Epoch 00047: val_f1_score did not improve from 0.94586\n",
      "Epoch 48/60\n",
      "31/31 [==============================] - 18s 587ms/step - loss: 0.0310 - f1_score: 0.9690 - val_loss: 0.0595 - val_f1_score: 0.9379\n",
      "\n",
      "Epoch 00048: val_f1_score did not improve from 0.94586\n",
      "Epoch 49/60\n",
      "31/31 [==============================] - 18s 586ms/step - loss: 0.0309 - f1_score: 0.9691 - val_loss: 0.0535 - val_f1_score: 0.9418\n",
      "\n",
      "Epoch 00049: val_f1_score did not improve from 0.94586\n",
      "Epoch 50/60\n",
      "31/31 [==============================] - 18s 586ms/step - loss: 0.0310 - f1_score: 0.9690 - val_loss: 0.0564 - val_f1_score: 0.9404\n",
      "\n",
      "Epoch 00050: val_f1_score did not improve from 0.94586\n",
      "Epoch 51/60\n",
      "31/31 [==============================] - 18s 586ms/step - loss: 0.0319 - f1_score: 0.9681 - val_loss: 0.0660 - val_f1_score: 0.9279\n",
      "\n",
      "Epoch 00051: val_f1_score did not improve from 0.94586\n",
      "Epoch 52/60\n",
      "31/31 [==============================] - 18s 587ms/step - loss: 0.0322 - f1_score: 0.9678 - val_loss: 0.0542 - val_f1_score: 0.9404\n",
      "\n",
      "Epoch 00052: val_f1_score did not improve from 0.94586\n",
      "Epoch 53/60\n",
      "31/31 [==============================] - 18s 587ms/step - loss: 0.0316 - f1_score: 0.9684 - val_loss: 0.0588 - val_f1_score: 0.9363\n",
      "\n",
      "Epoch 00053: val_f1_score did not improve from 0.94586\n",
      "Epoch 54/60\n",
      "31/31 [==============================] - 18s 587ms/step - loss: 0.0325 - f1_score: 0.9675 - val_loss: 0.0560 - val_f1_score: 0.9376\n",
      "\n",
      "Epoch 00054: val_f1_score did not improve from 0.94586\n",
      "Epoch 00054: early stopping\n"
     ]
    }
   ],
   "source": [
    "model = unet_v2(loss=losses[LOSS_FUNCTION],\n",
    "                metrics=[f1_score],\n",
    "                input_size=(IMG_WIDTH, IMG_HEIGHT, IMG_CHANNELS))\n",
    "\n",
    "history = model.fit(\n",
    "    train_gen(BATCH_SIZE),\n",
    "    steps_per_epoch=NUM_SAMPLES // BATCH_SIZE,\n",
    "    epochs=EPOCHS,\n",
    "    callbacks=[earlystopper, checkpointer],\n",
    "    validation_data=val_gen(BATCH_SIZE),\n",
    "    validation_steps=NUM_SAMPLES_VAL // BATCH_SIZE\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "wp8bhUfr_eRT"
   },
   "source": [
    "### Plot training & validation accuracy values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 312
    },
    "colab_type": "code",
    "executionInfo": {
     "elapsed": 1100,
     "status": "ok",
     "timestamp": 1588957633056,
     "user": {
      "displayName": "Francesco SACCANI",
      "photoUrl": "https://lh3.googleusercontent.com/a-/AOh14GiK1QlwNLRwoAq-pAnoW8HH9h9h2SvqIHGIEuyL=s64",
      "userId": "03506189413873966593"
     },
     "user_tz": -120
    },
    "id": "laWMsj6664mC",
    "outputId": "15585a3b-a3ea-4a5e-ed89-3453fa98e4b7"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<matplotlib.legend.Legend at 0x7f2579781400>"
      ]
     },
     "execution_count": 23,
     "metadata": {
      "tags": []
     },
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light",
      "tags": []
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "\n",
    "plt.plot(history.history['f1_score'])\n",
    "plt.plot(history.history['val_f1_score'])\n",
    "plt.title('Model F1-score')\n",
    "plt.ylabel('F1-score')\n",
    "plt.xlabel('Epoch')\n",
    "plt.legend(['Train', 'Validation'], loc='lower right')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "5jQAwCJ6_YHg"
   },
   "source": [
    "### Plot training & validation loss values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 312
    },
    "colab_type": "code",
    "executionInfo": {
     "elapsed": 1203,
     "status": "ok",
     "timestamp": 1588957634828,
     "user": {
      "displayName": "Francesco SACCANI",
      "photoUrl": "https://lh3.googleusercontent.com/a-/AOh14GiK1QlwNLRwoAq-pAnoW8HH9h9h2SvqIHGIEuyL=s64",
      "userId": "03506189413873966593"
     },
     "user_tz": -120
    },
    "id": "r6OoX-K464mK",
    "outputId": "22b556d3-87dd-4358-a097-3e7566880a25"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<matplotlib.legend.Legend at 0x7f2578b45ba8>"
      ]
     },
     "execution_count": 24,
     "metadata": {
      "tags": []
     },
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light",
      "tags": []
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "plt.plot(history.history['loss'])\n",
    "plt.plot(history.history['val_loss'])\n",
    "plt.title('Model loss')\n",
    "plt.ylabel('Loss')\n",
    "plt.xlabel('Epoch')\n",
    "plt.legend(['Train', 'Validation'], loc='upper right')"
   ]
  }
 ],
 "metadata": {
  "accelerator": "GPU",
  "colab": {
   "collapsed_sections": [],
   "name": "unet.ipynb",
   "provenance": [
    {
     "file_id": "https://github.com/franksacco/where-is-wally/blob/master/unet.ipynb",
     "timestamp": 1588430323472
    }
   ],
   "toc_visible": true
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
